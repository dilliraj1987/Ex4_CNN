{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpWbYXmilPUyqBufscQyxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilliraj1987/Ex4_CNN/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Required Libraries**"
      ],
      "metadata": {
        "id": "xAvCcEzQ8Np1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuqT_gE0FrLy",
        "outputId": "948b3e0d-b1b1-43fb-cc8a-66985250917a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GV_DeepLearning'...\n",
            "remote: Enumerating objects: 1607, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1607 (delta 4), reused 15 (delta 2), pack-reused 1589\u001b[K\n",
            "Receiving objects: 100% (1607/1607), 29.99 MiB | 36.83 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/vadivukar/GV_DeepLearning/\" # Command for cloning the related contents from github user \"vadivukar/GV_Deeplearning\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf #importing TensorFlow Module\n",
        "from keras.preprocessing.image import ImageDataGenerator #importing ImageDataGenerator for preprocessing"
      ],
      "metadata": {
        "id": "TIKowIVdL9jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__ #TensorFlow Version Display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F-RAV5-WM0W8",
        "outputId": "ecc040fc-8b3b-49de-c1b3-e8dc11359ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Augmentation**"
      ],
      "metadata": {
        "id": "r7BmyUzU8EgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True) # Image Rescale size = 256; Transformation of images range (shear_range = 20%); Zoom_range = 20%, Horizontal flip enabled  \n",
        "training_set = train_datagen.flow_from_directory('/content/GV_DeepLearning/Dataset/TrainingSet', target_size = (64,64), batch_size = 32, class_mode = 'binary') #Path of image directory for training; Target Image size = 64x64; Batch per epoch = 32; Classification type = Binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttDVKqfFM4im",
        "outputId": "ac216f01-928d-41da-bd61-4a1476839f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 692 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255) # Image Rescale size = 256\n",
        "test_set = test_datagen.flow_from_directory('/content/GV_DeepLearning/Dataset/TestSet', target_size = (64,64), batch_size = 32, class_mode = 'binary') #Path of image directory for testing; Target Image size = 64x64; Batch per epoch = 32; Classification type = Binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twuJtpg6N7Hc",
        "outputId": "fea01f9d-4e2a-4206-a0d2-d0e5006eedf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential() #CNN Linear sequential model funtion calling from keras.models"
      ],
      "metadata": {
        "id": "C5mskALgOVXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3])) #Conv_Layer1 in 2Dimensional with 32 filters, Kernel_size = 3; Activation_function = relu; Resize input image to 64x64 with RGB\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) #Max_Pooling in 2D with size of 2 and strides = 2"
      ],
      "metadata": {
        "id": "YfsJ5zOpOinm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) #Conv_Layer2 in 2Dimensional with 32 filters, Kernel_size = 3; Activation_function = relu\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) #Max_Pooling in 2D with size of 2 and strides = 2"
      ],
      "metadata": {
        "id": "C43aqxx_O_Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten()) #Flatten layer from keras forms the 1D array information to fully connected layer"
      ],
      "metadata": {
        "id": "9L4SaHW-PWeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation = 'relu')) # Fully connected with 128 hidden layers and relu activation function\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid')) # Output layer with activation function as 'sigmoid' to classify the to categories"
      ],
      "metadata": {
        "id": "axBArFd6Pfui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy']) ## Compiling done with the 'adam'(Adaptable Optimizer); Loss = binary_crossentropy; metric evaluation = accuracy"
      ],
      "metadata": {
        "id": "SN2V62FMRLIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20) # Model evaluation of accuracy for both training and testing set with 20 epoches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0w8ywYKRmfG",
        "outputId": "a43d7b71-6cbb-409f-e49c-6c3160001db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 8s 294ms/step - loss: 0.6970 - accuracy: 0.5434 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 7s 312ms/step - loss: 0.6537 - accuracy: 0.5824 - val_loss: 0.7915 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.6211 - accuracy: 0.6402 - val_loss: 0.6925 - val_accuracy: 0.5800\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.5830 - accuracy: 0.6806 - val_loss: 0.7331 - val_accuracy: 0.5500\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.5768 - accuracy: 0.6893 - val_loss: 0.6403 - val_accuracy: 0.6100\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 6s 277ms/step - loss: 0.5461 - accuracy: 0.7370 - val_loss: 0.6165 - val_accuracy: 0.6600\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5243 - accuracy: 0.7355 - val_loss: 0.6338 - val_accuracy: 0.6300\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.5145 - accuracy: 0.7514 - val_loss: 0.6154 - val_accuracy: 0.6400\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.5001 - accuracy: 0.7500 - val_loss: 0.6627 - val_accuracy: 0.6600\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 6s 269ms/step - loss: 0.4906 - accuracy: 0.7572 - val_loss: 0.7815 - val_accuracy: 0.6200\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 6s 283ms/step - loss: 0.4792 - accuracy: 0.7486 - val_loss: 0.6601 - val_accuracy: 0.6200\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 6s 268ms/step - loss: 0.4764 - accuracy: 0.7861 - val_loss: 0.8597 - val_accuracy: 0.5900\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 6s 272ms/step - loss: 0.4533 - accuracy: 0.7876 - val_loss: 0.6359 - val_accuracy: 0.6800\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.4558 - accuracy: 0.7645 - val_loss: 0.6692 - val_accuracy: 0.6600\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 6s 274ms/step - loss: 0.4939 - accuracy: 0.7529 - val_loss: 0.6364 - val_accuracy: 0.7000\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 6s 278ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.6721 - val_accuracy: 0.6500\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 6s 276ms/step - loss: 0.4069 - accuracy: 0.8107 - val_loss: 0.6606 - val_accuracy: 0.6900\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.3846 - accuracy: 0.8121 - val_loss: 0.7011 - val_accuracy: 0.6700\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 7s 329ms/step - loss: 0.4007 - accuracy: 0.8194 - val_loss: 0.6867 - val_accuracy: 0.6900\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 9s 410ms/step - loss: 0.3862 - accuracy: 0.8251 - val_loss: 0.5783 - val_accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0c7cb7650>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing the model**"
      ],
      "metadata": {
        "id": "I9hL9DDwm7t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Importing numpy library\n",
        "from keras.preprocessing import image # Importing image function from keras.preprocessing\n",
        "test_image = image.load_img('/content/GV_DeepLearning/Dataset/SingleImage/cat_or_dog_1.jpg', target_size = (64, 64)) #Load the test image from the test directory with target image size 64x64\n",
        "test_image = image.img_to_array(test_image) # Getting each pixel value of image in array by using numpy\n",
        "test_image = np.expand_dims(test_image, axis = 0) #To get the expanded dimensions of an array\n",
        "result = cnn.predict(test_image) #predicting the test image result through CNN\n",
        "training_set.class_indices # Providing index values for the classes of training_set \n",
        "if result[0][0] == 1: #if result = 1; Predicting as 'dog' else predicting as 'cat'\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "KmTv-w6VRs6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction) # Display final prediction output from the given input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mliXViOSrxO",
        "outputId": "ca4321cb-eacd-4557-def3-e7961f64844d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-e3N4WngS8Iv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}